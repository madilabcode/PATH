{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# PATH Model Tutorial\n",
        "\n",
        "This notebook demonstrates the complete workflow for using the PATH model (TransPath) for spatial transcriptomics analysis.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The PATH (TransPath) model is designed to analyze spatial transcriptomics data by extracting meaningful embeddings from tissue images and predicting pathway activities. This tutorial walks through:\n",
        "\n",
        "1. **Environment Setup**: Installing required libraries and cloning the PATH repository\n",
        "2. **Data & Model Retrieval**: Downloading pre-trained model weights and example datasets\n",
        "3. **Data Processing**: Loading and preprocessing spatial transcriptomics data (.h5ad format)\n",
        "4. **Model Inference**: Initializing the model, loading weights, and extracting embeddings\n",
        "5. **Downstream Analysis**: Clustering, pathway prediction, and visualization\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Python environment with CUDA support (recommended for GPU acceleration)\n",
        "- Sufficient disk space for model weights and datasets (~several GB)"
      ],
      "metadata": {
        "id": "fQ_dTka-Thaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "Install the required Python packages:\n",
        "- `scanpy`: For handling spatial transcriptomics data\n",
        "- `gdown`: For downloading files from Google Drive\n"
      ],
      "metadata": {
        "id": "3VzIX5Y6NNeH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSZ7xEqLD1TQ"
      },
      "outputs": [],
      "source": [
        "!pip install scanpy gdown\n",
        "!git clone https://github.com/madilabcode/PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Clone TransPath Repository\n",
        "\n",
        "Change to the PATH directory and run the setup script to clone the TransPath repository. This script will set up the necessary dependencies and directory structure."
      ],
      "metadata": {
        "id": "Q59JpNbzNWWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"PATH\")\n",
        "!chmod 777  ./clone_transpath.sh\n",
        "!./clone_transpath.sh"
      ],
      "metadata": {
        "id": "J-l7th3qEeY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Download Data and Model Weights\n",
        "\n",
        "Download the required files from Google Drive:\n",
        "- **hd_obj.h5ad**: Example spatial transcriptomics dataset (AnnData format)\n",
        "- **hd_wights.pth**: Pre-trained model weights for the PATH model\n",
        "- **mask_hd.pkl**: Pathway mask file defining which pathways to analyze\n",
        "- **timm.tar**: Timm library archive (vision transformer dependencies)"
      ],
      "metadata": {
        "id": "ACVvH8VtNd3H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b86eab6b"
      },
      "source": [
        "import gdown\n",
        "file_id_obj = \"1vICnccokrUrOTcNbNd-FXortyf0QNNGM\"\n",
        "output_path_obj = './data/hd_obj.h5ad'\n",
        "file_id_wights = \"1KXvTXc6XnPASSY652lOaF9ZQCvd0cCkk\"\n",
        "output_file_wights = './models/hd_wights.pth'\n",
        "file_id_mask = \"1uAIxdMRwCseJI4Dkr9tXRwcvGYJzn0x5\"\n",
        "output_file_mask = './data/mask_hd.pkl'\n",
        "file_id_timm =\"1L7dbztMHC-ipFrlILLcX8GXGne3mr6fZ\"\n",
        "out_put_timm = \"./timm.tar\"\n",
        "gdown.download(id=file_id_obj, output=output_path_obj, quiet=False)\n",
        "gdown.download(id=file_id_wights, output=output_file_wights, quiet=False)\n",
        "gdown.download(id=file_id_mask, output=output_file_mask, quiet=False)\n",
        "gdown.download(id=file_id_timm, output=out_put_timm, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Install Timm Library\n",
        "\n",
        "Install the timm (PyTorch Image Models) library from the downloaded archive. This library provides the vision transformer backbone used by the PATH model.\n",
        "session may need to rest - its ok\n"
      ],
      "metadata": {
        "id": "tIRb0My8LfyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm.tar igraph leidenalg"
      ],
      "metadata": {
        "id": "JfMQ9SOSK-H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Load Spatial Data\n",
        "\n",
        "Load the spatial transcriptomics data using scanpy"
      ],
      "metadata": {
        "id": "MEsgLujWNrnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scanpy as sc\n",
        "import os\n",
        "os.chdir(\"PATH\")\n",
        "obj = sc.read_h5ad('./data/hd_obj.h5ad')\n"
      ],
      "metadata": {
        "id": "awOACnslJGIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Process Coordinates and Load Mask\n",
        "\n",
        "Process the spatial coordinates from the AnnData object to extract image patches corresponding to each spot. Load the pathway mask that defines which KEGG pathways are included in the analysis.\n"
      ],
      "metadata": {
        "id": "9IoRx0d7N3Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scripts.Utils as ut\n",
        "import torch\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "imgs = ut.process_coord_obj_hd(obj)\n",
        "with open('./data/mask_hd.pkl', 'rb') as f:\n",
        "    mask = pickle.load(f)"
      ],
      "metadata": {
        "id": "iv6ixJGCJbXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Initialize PATH Model\n",
        "\n",
        "Create the PATH model with the following parameters:\n",
        "- `kegg_dim`: Number of pathways (determined by mask)\n",
        "- `lora_rank`: LoRA rank for efficient fine-tuning (8)\n",
        "- `num_slides`, `num_samples`, `num_datasets`: Dataset configuration parameters\n",
        "- `classification_mode`: Set to True for pathway prediction\n",
        "\n",
        "Load the pre-trained weights from the downloaded checkpoint.\n"
      ],
      "metadata": {
        "id": "Bc9JpJQhN8HF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import src.PATH as path\n",
        "model = path.create_model(kegg_dim=mask.sum(),lora_rank=8,num_slides=1, num_samples=1, num_datasets=1,classification_mode=True)\n",
        "model.load_model(r\"./models/hd_wights.pth\")"
      ],
      "metadata": {
        "id": "TRPb7y9UMkGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Create DataLoader\n",
        "\n",
        "Define a simple PyTorch Dataset class to handle the image data and create a DataLoader for batch processing. The batch size is set to 128 for efficient GPU utilization."
      ],
      "metadata": {
        "id": "yXXbMxsxOY-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class basic_dataset(Dataset):\n",
        "    def __init__(self, images):\n",
        "        self.images = images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx]\n",
        "\n",
        "dataloader = DataLoader(basic_dataset(imgs), batch_size=128, shuffle=False, drop_last=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "VRpKcq9EMqce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Extract Embeddings\n",
        "\n",
        "Extract embeddings from the PATH model for all spots in the dataset. These embeddings capture spatial and molecular features learned by the model.\n"
      ],
      "metadata": {
        "id": "HvxDXqiPOvuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = ut.get_embeddings(model, dataloader)\n"
      ],
      "metadata": {
        "id": "FUtIGGWsQlb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10: Clustering Analysis\n",
        "\n",
        "Perform downstream analysis using the extracted embeddings:\n",
        "\n",
        "1. Add embeddings to the AnnData object\n",
        "2. Compute k-nearest neighbors graph using the embeddings\n",
        "3. Perform Leiden clustering to identify spatial domains\n",
        "4. Visualize clusters on the spatial coordinates\n",
        "\n"
      ],
      "metadata": {
        "id": "8MfHpdZlO9DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "obj.obsm[\"X_embed\"] = encoded\n",
        "sc.pp.neighbors(obj, use_rep=\"X_embed\", n_neighbors=15)\n",
        "sc.tl.leiden(obj, resolution=0.15, key_added=\"embedding_leiden\")\n",
        "\n",
        "# See real number of clusters found\n",
        "num_leiden_clusters = len(obj.obs[\"embedding_leiden\"].unique())\n",
        "print(f\"Leiden clusters found: {num_leiden_clusters}\")\n",
        "\n",
        "# Plot clusters on spatial locations\n",
        "sc.pl.spatial(obj, color=\"embedding_leiden\", spot_size=100, show=False)\n"
      ],
      "metadata": {
        "id": "Zut3jbW8TrK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 12: Predict Pathway Activities\n",
        "\n",
        "Use the model's KEGG head to predict pathway activities from the extracted embeddings. This generates pathway activity scores for each spot, which can be used for downstream biological interpretation.\n",
        "\n",
        "**Note**: Ensure you have CUDA available for GPU acceleration, otherwise the model will run on CPU (slower).\n"
      ],
      "metadata": {
        "id": "ZdzW3JVwSiDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "predication_pd = model.kegg_head(torch.tensor(encoded).to(device))\n",
        "predication_pd = predication_pd.detach().cpu().numpy()\n",
        "predication_pd = pd.DataFrame(predication_pd, columns=mask[mask==True].index)\n",
        "predication_pd.columns.tolist()"
      ],
      "metadata": {
        "id": "dw1GgE_rSS_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj.obs[\"Cell cycle\"] = predication_pd[\"Cell cycle\"].values\n",
        "sc.pl.spatial(obj, color=\"Cell cycle\", spot_size=100, show=True)"
      ],
      "metadata": {
        "id": "H6o5Dn1MSp4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w6j54ivzSu7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 11: Pathway Activity Analysis\n",
        "\n",
        "Perform differential pathway activity analysis between clusters:\n",
        "\n",
        "1. **Statistical Testing**: Use Mann-Whitney U test to identify pathways enriched in each cluster compared to the rest\n",
        "2. **Multiple Testing Correction**: Apply Benjamini-Hochberg FDR correction\n",
        "3. **Visualization**: Create a clustered heatmap showing pathway activities across clusters\n",
        "\n",
        "The analysis identifies pathways that are significantly enriched in each spatial domain, providing biological insights into regional tissue function.\n"
      ],
      "metadata": {
        "id": "M-e4uHEmR-aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scripts.anaylsis as an\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "cluster_labels = obj.obs[\"embedding_leiden\"].values\n",
        "pathway_names = np.asarray(predication_pd.columns)  # keep your existing naming\n",
        "\n",
        "results_per_cluster, selected_pathways = an.cluster_vs_rest_pathways(\n",
        "    predictions=predication_pd,\n",
        "    cluster_labels=cluster_labels,\n",
        "    pathway_names=pathway_names,\n",
        "    fdr_thresh=0.05,\n",
        "    min_mean_diff=0.0,\n",
        "    alternative=\"greater\",\n",
        "    top_k_fallback=15,\n",
        ")\n",
        "\n",
        "# Build your cluster x pathway heatmap matrix using selected_pathways\n",
        "avg_pathways_df = pd.DataFrame(\n",
        "    [predication_pd[cluster_labels == c].mean(axis=0) for c in pd.unique(cluster_labels)],\n",
        "    index=[str(c) for c in pd.unique(cluster_labels)],\n",
        "    columns=pathway_names\n",
        ")\n",
        "\n",
        "heatmap_df = avg_pathways_df[selected_pathways]\n",
        "heatmap_df_z = heatmap_df.sub(heatmap_df.mean(axis=1), axis=0).div(heatmap_df.std(axis=1).replace(0, 1), axis=0)\n",
        "ax = sns.clustermap(heatmap_df_z.T, cmap=\"coolwarm\", figsize=(10, 20), vmin=-1.5, vmax=1.5)"
      ],
      "metadata": {
        "id": "NItqCa6-PdYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 12: Predict Pathway Activities\n",
        "\n",
        "Use the model's KEGG head to predict pathway activities from the extracted embeddings. This generates pathway activity scores for each spot, which can be used for downstream biological interpretation.\n",
        "\n",
        "**Note**: Ensure you have CUDA available for GPU acceleration, otherwise the model will run on CPU (slower).\n"
      ],
      "metadata": {
        "id": "F3bk8cUFSFXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "an.pca_anaylsis(predication_pd,obj)"
      ],
      "metadata": {
        "id": "om928IAkSBdD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}